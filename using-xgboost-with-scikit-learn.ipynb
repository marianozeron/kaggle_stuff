{"cells":[{"metadata":{"_uuid":"cdd204371f9f83d15616dab1a94370e1eba0d9b9"},"cell_type":"markdown","source":"# XGBoost\n\nExploring the use of XGBoost and its integration with Scikit-Learn.\n\nSome useful links:\n* [XGBoost documentation](https://xgboost.readthedocs.io/en/latest/index.html)\n* [Parameters](https://xgboost.readthedocs.io/en/latest/parameter.html)\n* [Python package](https://xgboost.readthedocs.io/en/latest/python/python_intro.html)\n* [Python examples](https://github.com/dmlc/xgboost/tree/master/demo/guide-python)\n* [scikit-learn examples](https://github.com/dmlc/xgboost/blob/master/demo/guide-python/sklearn_examples.py)\n* [Diabetes dataset](http://scikit-learn.org/stable/datasets/index.html#diabetes-dataset)\n* [Breast cancer dataset](http://scikit-learn.org/stable/datasets/index.html#breast-cancer-wisconsin-diagnostic-database)\n\nObjective is to demonstrate:\n* regression ✓\n* binary classification ✓\n* multiclass classification ✓\n* cross-validation ✓\n* hyperparameter searching ✓\n* feature importance ✓\n* early stopping ✓\n* evaluations\n* plotting ✓"},{"metadata":{"trusted":false,"_uuid":"4ab228c84471891201204c1c70c0e4535ff76db9"},"cell_type":"code","source":"import numpy as np\n\nfrom scipy.stats import uniform, randint\n\nfrom sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"63f609040e124bf1ef3b7853daab97c6be268312"},"cell_type":"code","source":"def display_scores(scores):\n    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6df117f0ea221d2a5fcc3232054d02757d50ec69"},"cell_type":"code","source":"def report_best_scores(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37811e5665f546205a98f9d7f77375fce4a1d9b9"},"cell_type":"markdown","source":"## Regression"},{"metadata":{"trusted":false,"_uuid":"e35bb62d5ea4622413443ff43d578e7b2893c309"},"cell_type":"code","source":"diabetes = load_diabetes()\n\nX = diabetes.data\ny = diabetes.target\n\nxgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n\nxgb_model.fit(X, y)\n\ny_pred = xgb_model.predict(X)\n\nmse=mean_squared_error(y, y_pred)\n\nprint(np.sqrt(mse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ab77663f37ec14488dbf542dc18d119ef726d2f8"},"cell_type":"code","source":"xgb_model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e675a3449f6d7f6fabd8b634195fde22c2cd670"},"cell_type":"markdown","source":"## Binary classification"},{"metadata":{"trusted":false,"_uuid":"21eee83d9068275fac549b80394d399b97edd2c5"},"cell_type":"code","source":"cancer = load_breast_cancer()\n\nX = cancer.data\ny = cancer.target\n\nxgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\nxgb_model.fit(X, y)\n\ny_pred = xgb_model.predict(X)\n\nprint(confusion_matrix(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bb24203c37935875a7628974d8748e4386aae80"},"cell_type":"markdown","source":"## Multiclass classification"},{"metadata":{"trusted":false,"_uuid":"84869c7bcb30f512af78b94ea768aa022264038d"},"cell_type":"code","source":"wine = load_wine()\n\nX = wine.data\ny = wine.target\n\nxgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\nxgb_model.fit(X, y)\n\ny_pred = xgb_model.predict(X)\n\nprint(confusion_matrix(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e79c504b5e909694f049100483d957f8f3b83bb7"},"cell_type":"markdown","source":"## Cross validation\n\nCross-validation using `KFold`"},{"metadata":{"trusted":false,"_uuid":"c55ecf8bcfbad2d6f2cfa90ea6f3e594323128d4"},"cell_type":"code","source":"diabetes = load_diabetes()\n\nX = diabetes.data\ny = diabetes.target\n\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\nscores = []\n\nfor train_index, test_index in kfold.split(X):   \n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    xgb_model = xgb.XGBRegressor(objective=\"reg:linear\")\n    xgb_model.fit(X_train, y_train)\n    \n    y_pred = xgb_model.predict(X_test)\n    \n    scores.append(mean_squared_error(y_test, y_pred))\n    \ndisplay_scores(np.sqrt(scores))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"352a19638053ea9e7e5993c324169e08d87c7434"},"cell_type":"markdown","source":"Cross-validation using `cross_val_score`"},{"metadata":{"trusted":false,"_uuid":"3aa271d172e729ea57b5c229f9ca60d49ffe7c46"},"cell_type":"code","source":"xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n\nscores = cross_val_score(xgb_model, X, y, scoring=\"neg_mean_squared_error\", cv=5)\n\ndisplay_scores(np.sqrt(-scores))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3830b4750c56d1cdd2e11529998dd36a05b2809"},"cell_type":"markdown","source":"## Hyperparameter searching"},{"metadata":{"trusted":false,"_uuid":"170c2d75670a537b2c06a59b4d31db380c811bb0"},"cell_type":"code","source":"diabetes = load_diabetes()\n\nX = diabetes.data\ny = diabetes.target\n\nxgb_model = xgb.XGBRegressor()\n\nparams = {\n    \"colsample_bytree\": uniform(0.7, 0.3),\n    \"gamma\": uniform(0, 0.5),\n    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n    \"max_depth\": randint(2, 6), # default 3\n    \"n_estimators\": randint(100, 150), # default 100\n    \"subsample\": uniform(0.6, 0.4)\n}\n\nsearch = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n\nsearch.fit(X, y)\n\nreport_best_scores(search.cv_results_, 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2aca70720de8182d89f49da579201263e184719c"},"cell_type":"markdown","source":"## Early stopping"},{"metadata":{"_uuid":"3d9ab8c42539d972bd731209cc3afc97cb761573"},"cell_type":"markdown","source":"The number of boosted trees (`n_estimators`) to train is uncapped, rather training continues until validation has not improved in *n* rounds"},{"metadata":{"trusted":false,"_uuid":"8151b8c5e80194c5b3b68b9ccf6b76ab57e6ae73"},"cell_type":"code","source":"cancer = load_breast_cancer()\n\nX = cancer.data\ny = cancer.target\n\n# if more than one evaluation metric are given the last one is used for early stopping\nxgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric=\"auc\")\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\nxgb_model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)])\n\ny_pred = xgb_model.predict(X_test)\n\naccuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24fc1730d1f767fd4f8134a9e781d223bcd53b8f"},"cell_type":"markdown","source":"`xgb_model.fit()` will produce a model from the last iteration, not the best one, so to get the optimum model consider retraining over `xgb_model.best_iteration` rounds."},{"metadata":{"trusted":false,"_uuid":"1e36599acc5b51f34822bad84a18078502479d4c"},"cell_type":"code","source":"print(\"best score: {0}, best iteration: {1}, best ntree limit {2}\".format(xgb_model.best_score, xgb_model.best_iteration, xgb_model.best_ntree_limit))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3dabdc10ad4747247a347c5e6bf50d0b3072a954"},"cell_type":"markdown","source":"## Evaluations"},{"metadata":{"trusted":false,"_uuid":"77d78fc754fdbdcef1e78713bdb44937c0224474"},"cell_type":"code","source":"cancer = load_breast_cancer()\n\nX = cancer.data\ny = cancer.target\n\nxgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators=20, random_state=42, eval_metric=[\"auc\", \"error\", \"error@0.6\"])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\nxgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n\ny_pred = xgb_model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1184be0ab9ca5995f68be62b4c3656e4e831a8f2"},"cell_type":"markdown","source":"## Plotting"},{"metadata":{"trusted":false,"_uuid":"900a1c9d1c993f789ec11c7db1bbfbc380daea04"},"cell_type":"code","source":"# requires graphviz and python-graphviz conda packages\nimport graphviz\n\ncancer = load_breast_cancer()\n\nX = cancer.data\ny = cancer.target\n\nxgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric=\"auc\")\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\nxgb_model.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_test, y_test)], verbose=False)\n\nxgb.plot_importance(xgb_model)\n\n# plot the output tree via matplotlib, specifying the ordinal number of the target tree\n# xgb.plot_tree(xgb_model, num_trees=xgb_model.best_iteration)\n\n# converts the target tree to a graphviz instance\nxgb.to_graphviz(xgb_model, num_trees=xgb_model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0fd60874beceed948748809922e8f05134ada2b1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}